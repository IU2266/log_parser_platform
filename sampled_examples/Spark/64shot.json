{"query": "Task 8 in stage 1.0 failed 4 times; aborting job", "answer": "Task {variables} in stage {variables} failed {variables} times; aborting job"}
{"query": "Will request 2 executor containers, each with 8 cores and 22528 MB memory including 2048 MB overhead", "answer": "Will request {variables} executor containers, each with {variables} cores and {variables} MB memory including {variables} MB overhead"}
{"query": "Excluding datanode DatanodeInfoWithStorage[10.10.34.15:50010,DS-8de4ae37-fac2-404a-a8e3-dcecd440f907,DISK]", "answer": "Excluding datanode DatanodeInfoWithStorage[{variables},{variables},{variables}]"}
{"query": "Resubmitting failed stages", "answer": "Resubmitting failed stages"}
{"query": "OutputCommitCoordinator stopped!", "answer": "OutputCommitCoordinator stopped!"}
{"query": "YarnClusterScheduler.postStartHook done", "answer": "YarnClusterScheduler.postStartHook done"}
{"query": "Got the output locations", "answer": "Got the output locations"}
{"query": "Started SparkUI at http://10.10.34.17:51244", "answer": "Started SparkUI at {variables}"}
{"query": "Unregistering ApplicationMaster with FAILED (diag message: Max number of executor failures (4) reached)", "answer": "Unregistering ApplicationMaster with {variables}"}
{"query": "Invoking stop() from shutdown hook", "answer": "Invoking stop() from shutdown hook"}
{"query": "Still have 1 requests outstanding when connection from mesos-master-1/10.10.34.11:34641 is closed", "answer": "Still have {variables} requests outstanding when connection from {variables} is closed"}
{"query": "Reporting 1066 blocks to the master.", "answer": "Reporting {variables} blocks to the master."}
{"query": "Got assigned task 1937", "answer": "Got assigned task {variables}"}
{"query": "running: Set()", "answer": "running: Set()"}
{"query": "Executor lost: 5 (epoch 0)", "answer": "Executor lost: {variables} (epoch {variables})"}
{"query": "Job 0 finished: collect at IPLoM.py:124, took 35.425973 s", "answer": "Job {variables} finished: collect at {variables}, took {variables} s"}
{"query": "Disabling executor 3.", "answer": "Disabling executor {variables}."}
{"query": "org.apache.spark.SparkException: Exception while starting container container_1485248649253_0055_01_000008 on host mesos-slave-09", "answer": "org.apache.spark.SparkException: Exception while starting container {variables} on host {variables}"}
{"query": "Submitting ResultStage 199 (PythonRDD[396] at count at IPLoM.py:520), which has no missing parents", "answer": "Submitting ResultStage {variables} ({variables} at {variables}), which has no missing parents"}
{"query": "BlockManagerMaster stopped", "answer": "BlockManagerMaster stopped"}
{"query": "looking for newly runnable stages", "answer": "looking for newly runnable stages"}
{"query": "ResultStage 188 (collect at IPLoM.py:672) finished in 0.525 s", "answer": "ResultStage {variables} (collect at {variables}) finished in {variables} s"}
{"query": "Started 13 remote fetches in 36 ms", "answer": "Started {variables} remote fetches in {variables} ms"}
{"query": "Resubmitting ShuffleMapStage 4 (reduceByKey at pnmf4.py:371) and ResultStage 5 (collect at pnmf4.py:377) due to fetch failure", "answer": "Resubmitting ShuffleMapStage {variables} (reduceByKey at {variables}) and ResultStage {variables} (collect at {variables}) due to fetch failure"}
{"query": "Waiting for application to be successfully unregistered.", "answer": "Waiting for application to be successfully unregistered."}
{"query": "Submitting ResultStage 2 (PythonRDD[5] at RDD at PythonRDD.scala:43), which has no missing parents", "answer": "Submitting ResultStage {variables} ({variables} at {variables}), which has no missing parents"}
{"query": "Successfully started service 'sparkExecutorActorSystem' on port 59200.", "answer": "Successfully started service {variables} on port {variables}."}
{"query": "Issue communicating with driver in heartbeater", "answer": "Issue communicating with driver in heartbeater"}
{"query": "ShuffleMapStage 4 is now unavailable on executor 3 (0/2, false)", "answer": "ShuffleMapStage {variables} is now unavailable on executor {variables} ({variables}, {variables})"}
{"query": "ResultStage 5 (collect at pnmf4.py:377) failed in 1052.368 s", "answer": "ResultStage {variables} (collect at {variables}) failed in {variables} s"}
{"query": "Registered signal handlers for [TERM, HUP, INT]", "answer": "Registered signal handlers for {variables}"}
{"query": "Python worker exited unexpectedly (crashed)", "answer": "Python worker exited unexpectedly (crashed)"}
{"query": "Input split: hdfs://10.10.34.11:9000/pjhe/logs/2kHPC.log:156039+4032", "answer": "Input split: {variables}+{variables}"}
{"query": "SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8", "answer": "SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: {variables}"}
{"query": "Stage 2 contains a task of very large size (1181 KB). The maximum recommended task size is 100 KB.", "answer": "Stage {variables} contains a task of very large size ({variables} KB). The maximum recommended task size is {variables} KB."}
{"query": "Registering RDD 5 (reduceByKey at pnmf4.py:332)", "answer": "Registering RDD {variables} (reduceByKey at {variables})"}
{"query": "Asked to send map output locations for shuffle 18 to mesos-slave-18:59641", "answer": "Asked to send map output locations for shuffle {variables} to {variables}"}
{"query": "ResultStage 18 (collect at pnmf4.py:296) finished in 2.396 s", "answer": "ResultStage {variables} (collect at {variables}) finished in {variables} s"}
{"query": "Error sending result RpcResponse{requestId=8054183328166237564, body=NioManagedBuffer{buf=java.nio.HeapByteBuffer[pos=0 lim=274 cap=274]}} to mesos-slave-05/10.10.34.15:34469; closing connection", "answer": "Error sending result RpcResponse{requestId={variables}, body={variables}} to {variables}; closing connection"}
{"query": "ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@10.10.34.30:50455)", "answer": "ApplicationMaster registered as NettyRpcEndpointRef(spark://{variables})"}
{"query": "Completed container container_1485248649253_0048_01_000006 on host: mesos-slave-08 (state: COMPLETE, exit status: -103)", "answer": "Completed container {variables} on host: {variables} (state: {variables}, exit status: {variables})"}
{"query": "Setting up ContainerLaunchContext", "answer": "Setting up ContainerLaunchContext"}
{"query": "Found inactive connection to mesos-slave-05/10.10.34.15:34412, creating a new one.", "answer": "Found inactive connection to {variables}, creating a new one."}
{"query": "BlockManager stopped", "answer": "BlockManager stopped"}
{"query": "Incomplete task interrupted: Attempting to kill Python Worker", "answer": "Incomplete task interrupted: Attempting to kill Python Worker"}
{"query": "failed: Set()", "answer": "failed: Set()"}
{"query": "Block broadcast_6_piece140 stored as bytes in memory (estimated size 4.0 MB, free 2.8 GB)", "answer": "Block {variables} stored as bytes in memory (estimated size {variables}, free {variables})"}
{"query": "SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(yarn, curi); users with modify permissions: Set(yarn, curi)", "answer": "SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set({variables}, {variables}); users with modify permissions: Set({variables}, {variables})"}
{"query": "Got job 18 (collect at pnmf4.py:296) with 48 output partitions", "answer": "Got job {variables} (collect at {variables}) with {variables} output partitions"}
{"query": "Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals", "answer": "Started progress reporter thread with (heartbeat : {variables}, initial allocation : {variables}) intervals"}
{"query": "Started SelectChannelConnector@0.0.0.0:50826", "answer": "Started SelectChannelConnector@{variables}"}
{"query": "Starting the user application in a separate Thread", "answer": "Starting the user application in a separate Thread"}
{"query": "Updating epoch to 24 and clearing cache", "answer": "Updating epoch to {variables} and clearing cache"}
{"query": "Starting job: count at pnmf4.py:351", "answer": "Starting job: count at {variables}"}
{"query": "MemoryStore cleared", "answer": "MemoryStore cleared"}
{"query": "Remoting shut down.", "answer": "Remoting shut down."}
{"query": "Driver 10.10.34.11:53494 disassociated! Shutting down.", "answer": "Driver {variables} disassociated! Shutting down."}
{"query": "Failed to fetch remote block broadcast_4_piece172 from BlockManagerId(6, mesos-master-2, 36003) (failed attempt 1)", "answer": "Failed to fetch remote block {variables} from BlockManagerId({variables}, {variables}, {variables}) (failed attempt {variables})"}
{"query": "Got told to re-register updating block broadcast_16_piece0", "answer": "Got told to re-register updating block {variables}"}
{"query": "Waiting for Spark driver to be reachable.", "answer": "Waiting for Spark driver to be reachable."}
{"query": "Registering MapOutputTracker", "answer": "Registering MapOutputTracker"}
{"query": "An unknown (mesos-master-1:35910) driver disconnected.", "answer": "An unknown ({variables}) driver disconnected."}
{"query": "Stage 1 was cancelled", "answer": "Stage {variables} was cancelled"}
{"query": "Shutting down remote daemon.", "answer": "Shutting down remote daemon."}
